{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae444728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c41137a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train\n",
    "X_train = X_train\n",
    "\n",
    "%store -r X_val\n",
    "X_val = X_val\n",
    "\n",
    "%store -r y_train\n",
    "y_train = y_train\n",
    "\n",
    "%store -r y_val\n",
    "y_val = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f6f75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVC\": SVC(probability=True, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1c20fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "🔹 Logistic Regression\n",
      "Test Accuracy: 0.7654\n",
      "Training Time: 0.0405 sec\n",
      "Prediction Time: 0.000728 sec\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.74      0.76      1424\n",
      "        True       0.75      0.79      0.77      1445\n",
      "\n",
      "    accuracy                           0.77      2869\n",
      "   macro avg       0.77      0.77      0.77      2869\n",
      "weighted avg       0.77      0.77      0.77      2869\n",
      "\n",
      "==================================================\n",
      "🔹 KNN\n",
      "Test Accuracy: 0.7654\n",
      "Training Time: 0.0020 sec\n",
      "Prediction Time: 3.611320 sec\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.78      0.77      1424\n",
      "        True       0.77      0.75      0.76      1445\n",
      "\n",
      "    accuracy                           0.77      2869\n",
      "   macro avg       0.77      0.77      0.77      2869\n",
      "weighted avg       0.77      0.77      0.77      2869\n",
      "\n",
      "==================================================\n",
      "🔹 SVC\n",
      "Test Accuracy: 0.7881\n",
      "Training Time: 9.9314 sec\n",
      "Prediction Time: 0.890653 sec\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.75      0.78      1424\n",
      "        True       0.77      0.83      0.80      1445\n",
      "\n",
      "    accuracy                           0.79      2869\n",
      "   macro avg       0.79      0.79      0.79      2869\n",
      "weighted avg       0.79      0.79      0.79      2869\n",
      "\n",
      "==================================================\n",
      "🔹 Random Forest\n",
      "Test Accuracy: 0.7835\n",
      "Training Time: 1.1757 sec\n",
      "Prediction Time: 0.082987 sec\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.80      0.79      1424\n",
      "        True       0.80      0.76      0.78      1445\n",
      "\n",
      "    accuracy                           0.78      2869\n",
      "   macro avg       0.78      0.78      0.78      2869\n",
      "weighted avg       0.78      0.78      0.78      2869\n",
      "\n",
      "==================================================\n",
      "🔹 Naive Bayes\n",
      "Test Accuracy: 0.7483\n",
      "Training Time: 0.0113 sec\n",
      "Prediction Time: 0.002666 sec\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.79      0.76      1424\n",
      "        True       0.77      0.71      0.74      1445\n",
      "\n",
      "    accuracy                           0.75      2869\n",
      "   macro avg       0.75      0.75      0.75      2869\n",
      "weighted avg       0.75      0.75      0.75      2869\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikolosova\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [15:26:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "🔹 XGBoost\n",
      "Test Accuracy: 0.7975\n",
      "Training Time: 0.3929 sec\n",
      "Prediction Time: 0.003434 sec\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.77      0.79      1424\n",
      "        True       0.78      0.82      0.80      1445\n",
      "\n",
      "    accuracy                           0.80      2869\n",
      "   macro avg       0.80      0.80      0.80      2869\n",
      "weighted avg       0.80      0.80      0.80      2869\n",
      "\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2933, number of negative: 2891\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1653\n",
      "[LightGBM] [Info] Number of data points in the train set: 5824, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503606 -> initscore=0.014423\n",
      "[LightGBM] [Info] Start training from score 0.014423\n",
      "==================================================\n",
      "🔹 LightGBM\n",
      "Test Accuracy: 0.7961\n",
      "Training Time: 0.5373 sec\n",
      "Prediction Time: 0.008997 sec\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.76      0.79      1424\n",
      "        True       0.78      0.83      0.80      1445\n",
      "\n",
      "    accuracy                           0.80      2869\n",
      "   macro avg       0.80      0.80      0.80      2869\n",
      "weighted avg       0.80      0.80      0.80      2869\n",
      "\n",
      "==================================================\n",
      "🔹 CatBoost\n",
      "Test Accuracy: 0.7999\n",
      "Training Time: 10.2494 sec\n",
      "Prediction Time: 0.014925 sec\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.76      0.79      1424\n",
      "        True       0.78      0.84      0.81      1445\n",
      "\n",
      "    accuracy                           0.80      2869\n",
      "   macro avg       0.80      0.80      0.80      2869\n",
      "weighted avg       0.80      0.80      0.80      2869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Train, predict, evaluate with timing\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Training time\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    # Prediction time\n",
    "    start_pred = time.time()\n",
    "    y_pred = model.predict(X_val)\n",
    "    end_pred = time.time()\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    train_time = end_train - start_train\n",
    "    pred_time = end_pred - start_pred\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Test Accuracy\": acc,\n",
    "        \"Train Time (s)\": train_time,\n",
    "        \"Prediction Time (s)\": pred_time\n",
    "    })\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"🔹 {name}\")\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.4f} sec\")\n",
    "    print(f\"Prediction Time: {pred_time:.6f} sec\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec5cfbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Model Comparison:\n",
      "                  Model  Test Accuracy  Train Time (s)  Prediction Time (s)\n",
      "7             CatBoost       0.799930       10.249419             0.014925\n",
      "5              XGBoost       0.797490        0.392875             0.003434\n",
      "6             LightGBM       0.796096        0.537251             0.008997\n",
      "2                  SVC       0.788079        9.931385             0.890653\n",
      "3        Random Forest       0.783548        1.175706             0.082987\n",
      "1                  KNN       0.765423        0.001997             3.611320\n",
      "0  Logistic Regression       0.765423        0.040546             0.000728\n",
      "4          Naive Bayes       0.748344        0.011261             0.002666\n"
     ]
    }
   ],
   "source": [
    "# 4. Compare results in a table\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "print(\"\\n📊 Model Comparison:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0b2f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Крос-валідація (StratifiedKFold зберігає баланс класів)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# 3. Список моделей\n",
    "models = {\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bad3863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 2601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1651\n",
      "[LightGBM] [Info] Number of data points in the train set: 5241, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503721 -> initscore=0.014883\n",
      "[LightGBM] [Info] Start training from score 0.014883\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2639, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1653\n",
      "[LightGBM] [Info] Number of data points in the train set: 5241, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503530 -> initscore=0.014120\n",
      "[LightGBM] [Info] Start training from score 0.014120\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2639, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1652\n",
      "[LightGBM] [Info] Number of data points in the train set: 5241, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503530 -> initscore=0.014120\n",
      "[LightGBM] [Info] Start training from score 0.014120\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2639, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1652\n",
      "[LightGBM] [Info] Number of data points in the train set: 5241, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503530 -> initscore=0.014120\n",
      "[LightGBM] [Info] Start training from score 0.014120\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1652\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503625 -> initscore=0.014499\n",
      "[LightGBM] [Info] Start training from score 0.014499\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1652\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503625 -> initscore=0.014499\n",
      "[LightGBM] [Info] Start training from score 0.014499\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1653\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503625 -> initscore=0.014499\n",
      "[LightGBM] [Info] Start training from score 0.014499\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1653\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503625 -> initscore=0.014499\n",
      "[LightGBM] [Info] Start training from score 0.014499\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1652\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503625 -> initscore=0.014499\n",
      "[LightGBM] [Info] Start training from score 0.014499\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 2602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1652\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503625 -> initscore=0.014499\n",
      "[LightGBM] [Info] Start training from score 0.014499\n",
      "==================================================\n",
      "🔹 LightGBM\n",
      "Accuracy per fold: [0.81989708 0.7838765  0.80617496 0.7941681  0.81099656 0.81443299\n",
      " 0.8161512  0.81443299 0.81443299 0.81786942]\n",
      "Mean Accuracy: 0.8092 (+/- 0.0110)\n",
      "==================================================\n",
      "🔹 CatBoost\n",
      "Accuracy per fold: [0.81818182 0.79759863 0.79759863 0.80960549 0.84020619 0.81443299\n",
      " 0.82646048 0.80584192 0.81271478 0.79896907]\n",
      "Mean Accuracy: 0.8122 (+/- 0.0130)\n"
     ]
    }
   ],
   "source": [
    "# 4. Оцінка моделей\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Mean Accuracy\": scores.mean(),\n",
    "        \"Std Dev\": scores.std()\n",
    "    })\n",
    "    print(\"=\"*50)\n",
    "    print(f\"🔹 {name}\")\n",
    "    print(\"Accuracy per fold:\", scores)\n",
    "    print(f\"Mean Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40357ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Cross-Validation Results:\n",
      "       Model  Mean Accuracy   Std Dev\n",
      "1  CatBoost       0.812161  0.012951\n",
      "0  LightGBM       0.809243  0.010953\n"
     ]
    }
   ],
   "source": [
    "# 5. Порівняльна таблиця\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Mean Accuracy\", ascending=False)\n",
    "print(\"\\n📊 Cross-Validation Results:\\n\", results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
